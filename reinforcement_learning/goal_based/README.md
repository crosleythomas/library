---
layout: default
title: Goal Based RL
---

# Goal Based RL

| Year | Title | Authors | Affiliation | Code | Other |
| --- | --- | --- | --- | --- | --- |
| 2015 | [Universal Value Function Approximators](papers/universal_value_function_approximators.pdf "Value functions are a core component of reinforcement learning systems. The main idea is to to construct a single function approximator V (s; theta) that estimates the long-term reward from any state s, using parameters theta. In this paper we introduce universal value function approximators (UVFAs) V (s; g; theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.") | Tom Schaul, Dan Horgan, Karol Gregor, David Silver | DeepMind | | |